一、Python爬虫项目简介
1）背景
为缅怀金庸老先生，特此写一个Python爬虫抓取金庸全集，方便日后研读。

2）项目环境
操作系统：Window10 LTSC 2019
编辑器：Visual Studio Code（Version：1.37.1）
Python库：requests请求库、BeautifulSoup4、lxml解析库、以及Python内置的os、re、time库等

3）最终目的
从指定网站抓取金庸全集小说，并保存到本地（用文本文件保存）

二、项目思路
1）爬虫的介绍
爬虫说到底就是给定一个网站的url，让你去获取对你有用的东西（比如数据、图片、音频等等）。为了拿到自己想要的数据，所以要利用一切技术手段来解析目标网站url并从中解析后的网站中获取数据。
所以，要简要介绍介绍一下Python3爬虫的请求库、解析库等。

2）组件库的介绍
requests请求库是用来请求目标网站url的，返回的是reponse对象。
BeautifulSoup4是解析库，用于解析reponse对象。
至于用何种方式解析，不尽相同。有的使用正则表达式解析、有的使用lxml方式解析等。

3）核心思路
两个类，一个是得到书籍信息的类GetBookInfo，比如页面链接、起始页面、终止页面、书名；
还有一个是得到金庸全集小说内容的类JyFiction；

步骤：
a）分析目标网址的url
b）从url中获取书籍的中文名和实际书籍的url
    i.根据实际url进一步获取书籍的起始页面的链接和章节终止页面的链接（分析网址可知其id是有递减规律的）
    ii.将获取到的url、book_name、start_id、end_id保存到一个jyBookInfo.txt的文本文件中
    iii.读取jyBookInfo.txt的文本文件中的书籍信息，进一步爬取每个章节的具体内容，并保存到本地。
c）为避免爬虫被目标主机所限制（比如禁封ip等），所以设置每隔2s访问一本书的目标链接
    
    
    
    
    
    
    
    
    
    
    
    
    
    